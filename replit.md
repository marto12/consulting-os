# Consulting OS MVP

## Overview

Consulting OS is a cloud-hosted MVP that demonstrates sequenced AI agents operating on shared, persistent project state with human approval gates. It follows a consulting workflow pattern where users create projects with objectives and constraints, then run AI agents through a structured pipeline: Issues Tree → Hypotheses & Analysis Plan → Execution (with real tool calling) → Executive Summary. Each stage requires human approval before the next can proceed.

The app is built as an Expo React Native application (targeting web primarily) with an Express.js backend and PostgreSQL database. It supports both real OpenAI LLM calls and a mock mode when no API key is configured.

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Frontend (Expo / React Native)

- **Framework**: Expo SDK 54 with expo-router for file-based routing
- **State Management**: TanStack React Query for server state, with `queryClient` and `apiRequest` helpers in `lib/query-client.ts`
- **Routing**: Tab-based navigation with two tabs — `app/(tabs)/index.tsx` (Projects: project list/creation) and `app/(tabs)/settings.tsx` (Settings: agent configuration admin panel). `app/project/[id].tsx` is a stack screen pushed above the tabs for project detail with tabbed interface for overview, issues, hypotheses, runs, summary, and logs
- **Styling**: React Native StyleSheet with a centralized color palette in `constants/colors.ts`
- **Fonts**: Inter (400, 500, 600, 700) via `@expo-google-fonts/inter`
- **Key Libraries**: react-native-gesture-handler, react-native-reanimated, react-native-keyboard-controller, react-native-safe-area-context
- **API Communication**: All API calls go through `apiRequest()` which constructs URLs from `EXPO_PUBLIC_DOMAIN` environment variable

### Backend (Express.js)

- **Server**: Express 5 running on the server, defined in `server/index.ts`
- **Routes**: Registered in `server/routes.ts` — handles project CRUD, stage transitions (approve/run-next), and data retrieval for issues, hypotheses, analysis plans, model runs, narratives, and run logs
- **CORS**: Dynamic CORS based on Replit domain environment variables, plus localhost support for development

### Workflow Engine

The core business logic enforces a strict stage-based workflow with these transitions:

```
created → issues_draft → issues_approved → hypotheses_draft → hypotheses_approved → execution_done → execution_approved → summary_draft → summary_approved → complete
```

- **Pending stages** (require approval): `issues_draft`, `hypotheses_draft`, `execution_done`, `summary_draft`
- **Run-next mapping**: Only allowed from approved/created stages to the next draft stage
- **Approval mapping**: Each draft/done stage maps to its approved/complete counterpart

### AI Agents (`server/agents/`)

- **Architecture**: Four sequential agents — Issues Tree, Hypothesis, Execution, and Summary
- **LLM Integration**: Uses OpenAI SDK pointed at Replit AI Integrations (`AI_INTEGRATIONS_OPENAI_API_KEY` and `AI_INTEGRATIONS_OPENAI_BASE_URL`). Model: `gpt-5-nano`
- **Mock Mode**: When no API key is present, agents return deterministic stub outputs so the app still functions
- **Tool Calling**: The execution agent uses a scenario calculator tool (`server/agents/scenario-tool.ts`) that performs financial scenario analysis (baseline, optimistic, pessimistic projections with NPV calculations)
- **JSON Extraction**: Agent responses are parsed from LLM output using regex to find JSON blocks in markdown code fences or raw JSON

### Database (PostgreSQL + Drizzle ORM)

- **ORM**: Drizzle ORM with PostgreSQL dialect
- **Schema Location**: `shared/schema.ts` — shared between frontend (for types) and backend
- **Connection**: `server/db.ts` creates a pg Pool from `DATABASE_URL` environment variable
- **Schema Push**: Use `npm run db:push` (drizzle-kit push) to sync schema to database

**Core Tables:**
- `projects` — id, name, objective, constraints, stage, timestamps
- `issue_nodes` — id, project_id, parent_id, text, priority, version, timestamps (tree structure)
- `hypotheses` — id, project_id, issue_node_id, statement, metric, data_source, method, version, timestamps
- `analysis_plan` — id, project_id, hypothesis_id, method, parameters_json, required_dataset, timestamps
- `model_runs` — audit log of agent executions (inputs, outputs, stage, status, timestamps)
- `narratives` — executive summaries generated by the summary agent
- `run_logs` — detailed logging of every agent run

**Additional Tables (from Replit integrations):**
- `conversations` — chat conversation metadata
- `messages` — chat messages linked to conversations

### Storage Layer

- `server/storage.ts` exports a `storage` object with methods for all database operations (CRUD for each table, stage updates, etc.)

### Replit Integration Modules (`server/replit_integrations/`)

Pre-built integration modules included but not central to the consulting workflow:
- **Chat**: Conversation CRUD with streaming LLM responses
- **Audio**: Voice recording, speech-to-text, text-to-speech with format detection and ffmpeg conversion
- **Image**: Image generation via `gpt-image-1`
- **Batch**: Rate-limited batch processing with retry logic (uses `p-limit` and `p-retry`)

### Build System

- **Development**: Two processes — `expo:dev` (Expo Metro bundler) and `server:dev` (tsx for server with hot reload)
- **Production Build**: `expo:static:build` runs a custom build script (`scripts/build.js`), `server:build` uses esbuild to bundle server code
- **Production Run**: `server:prod` serves the built application

## External Dependencies

### Required Services
- **PostgreSQL**: Database provisioned via Replit, connection string in `DATABASE_URL` environment variable
- **Replit AI Integrations (OpenAI-compatible)**: LLM calls for AI agents. Configured via `AI_INTEGRATIONS_OPENAI_API_KEY` and `AI_INTEGRATIONS_OPENAI_BASE_URL`. App works in mock mode without these.

### Key NPM Dependencies
- **expo** (~54.0.27): React Native framework
- **expo-router** (~6.0.17): File-based routing
- **express** (^5.0.1): Backend HTTP server
- **drizzle-orm** (^0.39.3) + **drizzle-kit**: Database ORM and migration tooling
- **openai** (^6.22.0): OpenAI API client for LLM calls
- **@tanstack/react-query** (^5.83.0): Server state management
- **pg** (^8.16.3): PostgreSQL client
- **zod** + **drizzle-zod**: Schema validation
- **p-limit** / **p-retry**: Rate limiting and retry utilities for batch processing

### Environment Variables
| Variable | Purpose |
|----------|---------|
| `DATABASE_URL` | PostgreSQL connection string (required) |
| `AI_INTEGRATIONS_OPENAI_API_KEY` | OpenAI API key via Replit integrations (optional, mock mode without) |
| `AI_INTEGRATIONS_OPENAI_BASE_URL` | OpenAI base URL via Replit integrations (optional) |
| `EXPO_PUBLIC_DOMAIN` | Public domain for API calls from frontend |
| `REPLIT_DEV_DOMAIN` | Replit development domain (set automatically) |
| `REPLIT_DOMAINS` | Replit deployment domains for CORS (set automatically) |